\chapter{结论与思考}


虽然我们的想法来源与短文本理解时的概念飙升，但是在我们的对话系统上加上图片视觉表达关联的相似的帖子之后我们只取得了微弱的提升。我们在短文本的一个特例——词的视觉表达上特别是在诗集上和高频率的词上的视觉表达取得了很好的效果，也因此训练出了一个效果良好的视觉分类器。在几次的结果中来看，我们的加入图像寻找相似的帖子能取得微弱的提升。如果仅仅从寻找相似的帖子这个字过程看，我们的确能寻找到很多正面的典型的例子。但是为什么文字的关联加上图片关联比单纯的文字关联只取得了微弱进步？一方面在微博数据中能视觉表达的帖子的比例太少，我们可能不倾向于写一个描述性的或者说容易视觉表达的帖子，我们更喜欢议论一些东西，吐槽一些东西，比如“不悔梦归处，只因太匆匆”。一方面可能上我们还没有找到将短文本在计算机中视觉表达的合适方法，比如“自由”作为单词的时候我们可以用“自由女神”表示，但是在一个谈论自由的帖子中就不那么合适。我们可能不如Word2Vec类似文字在图像中关联算法，是我们需要图片搜索引擎搜索图片来完成视觉表达这样一个过程，而不是直接地相互关联。

我们在这篇文章中提出了一些关于短文本相似度计算新的想法，少数关于这方面的资料用的图像识别的方法还停留在SIFTs时代。\cite{bergsma2011learning}这几年随着深度学习的发展，图像识别技术在卷积神经网络中的巨大进步，图像识别的精度大大提升，另一方面图像和文本的相关联的资料也还在增多。期待在这个方向上看到更好的发展。

